{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDGAR Financial Data Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full documentation about usage and dependencies can be viewed at [README.md](README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_content(html_content: str) -> str:\n",
    "    \"\"\" \n",
    "    Function to clean the contents of HTML by removing the unnecessary tags\n",
    "    and restructuring the contents\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove the html tags\n",
    "    html_content = re.sub(r'</\\w+>', '\\n', html_content)\n",
    "    html_content = re.sub(r'<\\w+>', '', html_content)\n",
    "    html_content = re.sub(r'<\\w+/>', '', html_content)\n",
    "    html_content = re.sub(r'<\\w+\\s.*>', '', html_content)\n",
    "    html_content = re.sub(r'<!.*>', '', html_content)\n",
    "\n",
    "    # Remove enters\n",
    "    html_content = '\\n'.join(line for line in html_content.split('\\n') if line.strip() != '')\n",
    "\n",
    "    # Reformat the texts\n",
    "    html_content = re.sub(r'\\n\\s+', '\\n', html_content)\n",
    "    html_content = re.sub(r'\\n\\)', ')', html_content)\n",
    "    html_content = re.sub(r'\\$\\s*\\n', '$', html_content)\n",
    "    html_content = re.sub(r'\\n\\s*%', '%', html_content)\n",
    "    html_content = re.sub(r'\\(\\$', '$(', html_content)\n",
    "    html_content = re.sub(r'\\s+\\)', ')', html_content)\n",
    "    html_content = re.sub(r'(\\$[\\d.,]+)\\s+\\n', r'\\1\\n', html_content)\n",
    "\n",
    "    return html_content\n",
    "\n",
    "def extract_eps(html_content: str) -> str:\n",
    "    \"\"\" \n",
    "    Function to extract the value of the EPS\n",
    "    \"\"\"\n",
    "\n",
    "    # Define eps_patterns for searching\n",
    "    eps_patterns = [\n",
    "        r'[Bb]asic and diluted earnings per share\\n(.*)\\n',\n",
    "        r'[Cc]ore earnings per share\\n\\$(.*)\\n',\n",
    "        r'Earnings \\(loss\\) per share from continuing operations\\nNet loss attributable to Valaris\\n.*\\n\\$(.*)\\n',\n",
    "        r'(?i)earnings per basic\\/diluted share.*?\\n(?:.*?\\n)*?\\$([\\d.]+)\\s?\\/\\s?\\$',\n",
    "        # r'(?i)(?:^.*\\b(?:earnings|income|per|share)\\b.*\\n)?\\bbasic\\b.*?\\b(?:per|share)?\\b.*?\\n(?:.*?\\n){0,2}?\\$(.*)',\n",
    "        # r'(?i)(?:^.*\\b(?:earnings|income|per|share)\\b.*\\n)?\\b(?:earnings|basic)\\b.*?\\b(?:per|share)?\\b.*?\\n(?:.*?\\n){0,2}?\\$([\\d.\\(\\)]+)\\n',\n",
    "        r'(?i)(?:^.*(?:earnings|income|per|share).*\\n)?basic.*?(?:per|share)?.*?\\n(?:.*?\\n){0,2}?\\$([\\d.\\(\\)]+)\\n',\n",
    "    ]\n",
    "\n",
    "    # Define loss patterns in case there is no eps\n",
    "    loss_patterns = [\n",
    "        r'(?i)Net \\(loss\\).*?per share.*?\\n\\$(.*)\\n',\n",
    "        r'(?i)Net \\(Loss\\) Earnings\\nBasic\\n\\$(.*)\\n',\n",
    "    ]\n",
    "\n",
    "    # Search for eps_patterns \n",
    "    # if there is no eps, search for loss value\n",
    "    for eps_pattern in eps_patterns:\n",
    "        eps_match = re.search(eps_pattern, html_content, re.MULTILINE)\n",
    "        if eps_match:\n",
    "            eps = eps_match.group(1)\n",
    "            break\n",
    "        else:\n",
    "            for loss_pattern in loss_patterns:\n",
    "                loss_match = re.search(string=html_content, pattern=loss_pattern)\n",
    "                if loss_match:\n",
    "                    eps = loss_match.group(1)\n",
    "                    break\n",
    "    return eps\n",
    "\n",
    "def extract_negative_value(eps: str) -> float:\n",
    "    \"\"\" \n",
    "    Function to properly convert the value in a parentheses to a negative value\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the negative value\n",
    "    eps_minus_match = re.search(pattern=r'\\(([\\d.]+)\\)', string=eps)\n",
    "\n",
    "    # Add the minus sign\n",
    "    if eps_minus_match:\n",
    "        eps = -1 * float(eps_minus_match.group(1)) \n",
    "    else:\n",
    "        eps = float(eps)\n",
    "\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the file names\n",
    "file_names = os.listdir(path=r'./data/')\n",
    "file_names = [file_name.split(sep='.')[0] for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list for a dataframe\n",
    "df = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Define the path to the files\n",
    "    input_file_path = os.path.join('./data/', f'{file_name}.html')\n",
    "\n",
    "    # Read the file from the list\n",
    "    with open(file=input_file_path, mode='r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "        # Clean the html content\n",
    "        html_content = clean_html_content(html_content)\n",
    "\n",
    "        # Extract the eps value\n",
    "        eps = extract_eps(html_content)\n",
    "\n",
    "        # Correct convert the value to negative if it is enclosed by parentheses\n",
    "        eps = extract_negative_value(eps)\n",
    "\n",
    "        # Add the eps value to the result dataframe\n",
    "        df.append({'filename': file_name, 'EPS': eps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the Results and Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a unit test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eps_extraction(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Function to test the EPS extraction from the dataframe.\n",
    "    This function asserts that the EPS values for specific filenames\n",
    "    in the dataframe are as expected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check the given test cases\n",
    "    assert df.loc[df.filename == '0001564590-20-019726', 'EPS'].values[0] == 0.08\n",
    "    assert df.loc[df.filename == '0000066570-20-000013', 'EPS'].values[0] == 1.12\n",
    "    assert df.loc[df.filename == '0000008947-20-000044', 'EPS'].values[0] == -0.41\n",
    "    assert df.loc[df.filename == '0001564590-20-019431', 'EPS'].values[0] == 1.08\n",
    "    assert df.loc[df.filename == '0001564590-20-019396', 'EPS'].values[0] == -3.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>EPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000004977-20-000054</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000008947-20-000044</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000046080-20-000050</td>\n",
       "      <td>-0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000066570-20-000013</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000314808-20-000062</td>\n",
       "      <td>-15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000706129-20-000012</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000846617-20-000024</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000874766-20-000033</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0001323885-20-000027</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0001373715-20-000098</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0001423689-20-000040</td>\n",
       "      <td>-4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0001436425-20-000011</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0001538263-20-000014</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001564590-20-019396</td>\n",
       "      <td>-3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0001564590-20-019421</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0001564590-20-019431</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0001564590-20-019442</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0001564590-20-019726</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename    EPS\n",
       "0   0000004977-20-000054   0.78\n",
       "1   0000008947-20-000044  -0.41\n",
       "2   0000046080-20-000050  -0.51\n",
       "3   0000066570-20-000013   1.12\n",
       "4   0000314808-20-000062 -15.19\n",
       "5   0000706129-20-000012   0.26\n",
       "6   0000846617-20-000024   0.47\n",
       "7   0000874766-20-000033   1.34\n",
       "8   0001323885-20-000027  -0.42\n",
       "9   0001373715-20-000098   0.25\n",
       "10  0001423689-20-000040  -4.46\n",
       "11  0001436425-20-000011   0.21\n",
       "12  0001538263-20-000014   0.07\n",
       "13  0001564590-20-019396  -3.15\n",
       "14  0001564590-20-019421  -0.24\n",
       "15  0001564590-20-019431   1.08\n",
       "16  0001564590-20-019442   1.00\n",
       "17  0001564590-20-019726   0.08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a dataframe\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Test the data correctness\n",
    "test_eps_extraction(df)\n",
    "\n",
    "# Show the results\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell below, the results will be generated in the CSV file called [results.csv](results.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "df.to_csv(r'.\\results.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
